# Balloon Detection with YOLOv5 and ViT Transformer Integration

**Project Background**  
This project was developed as part of the **Emerging Technologies and AI** course in the **Data Science Master's program at HTW Berlin (3rd Semester)**. The challenge involves object detection using transformer-based approaches and YOLOv5, with a focus on detecting balloons in images. The project follows a complete machine learning workflow, including dataset selection, data processing, model definition, and training.

## Table of Contents
1. [Objectives](#objectives)
2. [Project Workflow](#project-workflow)
3. [Dataset](#dataset)
4. [Modeling Approach](#modeling-approach)
5. [Setup and Installation](#setup-and-installation)
6. [Usage](#usage)
7. [Results](#results)
8. [Future Work](#future-work)

---

## Objectives

The main objective of this project is to create an accurate balloon detection model using a combination of **Vision Transformers (ViT)** and **YOLOv5**. Key goals include:
- Selecting and understanding a suitable dataset for balloon detection.
- Defining the necessary data processing and image formatting steps for transformer-based models.
- Implementing YOLOv5 with ViT transformations for enhanced detection accuracy.
- Training and evaluating the model with an emphasis on understanding object detection probabilities.

## Project Workflow

### 1. Dataset Search and Selection
- **Search for Datasets**: Researched and evaluated various datasets to find one suitable for detecting balloons.
- **Selection**: Chose a dataset with high-quality images containing balloons to ensure training accuracy and generalizability.

### 2. Data Understanding and Preprocessing
- **Data Understanding**: Explored the data characteristics, including image size, quality, and the nature of the balloon annotations.
- **Image Formatting**: Resized and transformed images to 64x64 pixels, which are appropriate for feeding into Vision Transformers (ViT) and YOLOv5.

### 3. Model Definition
- **Learning Framework**: Defined a YOLOv5 model adapted to work with ViT transformations, preparing the model for both spatial and transformer-based detection learning.
- **Transformer Integration**: Applied ViT transformations to capture spatial relationships in images before feeding them into YOLOv5.
  
### 4. Training and Evaluation
- **Training**: Initiated the training process with a specific focus on balloon detection.
- **Detection Probability Check**: Analyzed detection probabilities generated by YOLOv5, refining the model to ensure high accuracy for balloons with confidence levels set at a minimum threshold of 80%.
  
## Dataset

- **Name**: Balloons
- **Source**: https://www.kaggle.com/datasets/serhiibiruk/balloon-object-detection
- **Description**: The dataset contains images annotated for balloon detection. Each image is formatted to be compatible with YOLOv5â€™s input requirements and ViT transformations.

## Modeling Approach

1. **YOLOv5 Model Configuration**: Custom YOLOv5 configuration (`yolov5s_efficientnet.yaml`) adapted for use with ViT transformations.
2. **Vision Transformer (ViT)**: Transformer architecture applied to the image data, enabling effective object detection through learned spatial relationships.
3. **Integration and Training**: The dataset was formatted and preprocessed, then fed into the YOLO model integrated with ViT for a robust detection pipeline.

## Setup and Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/balloon-detection-yolo.git
   cd balloon-detection-yolo
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Mount Google Drive and copy over your data files if using Colab:
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

4. Run the training script (fast but bad a and r):
   ```bash
   python train.py --img 64 --batch 4 --epochs 5 --data data.yaml --cfg models/yolov5s_efficientnet.yaml --weights yolov5n.pt --name balloon_detector
   ```

5.Run the training script (slow but good a and r):
  ```bash
   python train.py --img 320 --batch 4 --epochs 5 --data /content/data.yaml --cfg models/yolov5m.yaml --weights yolov5m.pt --name balloon_detector
   ```

## Usage

1. **Run Inference on a Single Image**:
   ```python
   results = model('/path/to/image.jpg')
   results.show()
   ```

2. **Evaluate Model on Test Data**:
   Use a loop to run inference on each image in the validation set and display detection results.

## Results

- Achieved a detection accuracy with a minimum confidence threshold of 80%.
- Model performance metrics include precision, recall, and mAP scores.

## Future Work

- **Hyperparameter Tuning**: Experiment with larger image sizes, batch sizes, and more epochs for potential performance improvements.
- **Model Deployment**: Package the trained model into a web or mobile application for real-time balloon detection.
- **Enhanced Transformer Integration**: Explore deeper integration with Vision Transformer layers to improve detection robustness.

---

**Contributors**  
Peter G.  
Data Science Master's Student, HTW Berlin  

**License**  
This project is licensed under the MIT License.
